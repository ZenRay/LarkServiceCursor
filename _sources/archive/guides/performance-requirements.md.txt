# æ€§èƒ½éœ€æ±‚ä¸æµ‹è¯•è§„èŒƒ

**ç‰ˆæœ¬**: 1.0.0
**æ›´æ–°æ—¶é—´**: 2026-01-15
**çŠ¶æ€**: Draft

---

## ğŸ“Š æ€§èƒ½ç›®æ ‡ (CHK025, CHK026)

### æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ ID | æŒ‡æ ‡åç§° | ç›®æ ‡å€¼ | éªŒè¯æ–¹æ³• |
|---------|---------|--------|---------|
| **P001** | å¹¶å‘ API è°ƒç”¨ååé‡ | â‰¥ 100 æ¬¡/ç§’ | å‹åŠ›æµ‹è¯• |
| **P002** | Token è‡ªåŠ¨å¤„ç†æˆåŠŸç‡ | â‰¥ 99.9% | ç»Ÿè®¡åˆ†æ |
| **P003** | API å“åº”æ—¶é—´ (P99) | â‰¤ 2 ç§’ | æ€§èƒ½ç›‘æ§ |
| **P004** | Token åˆ·æ–°è€—æ—¶ | â‰¤ 500ms | å•å…ƒæµ‹è¯• |
| **P005** | æ•°æ®åº“æŸ¥è¯¢è€—æ—¶ | â‰¤ 50ms | æ€§èƒ½æµ‹è¯• |

---

## ğŸ¯ P001: å¹¶å‘ API è°ƒç”¨ååé‡ (â‰¥ 100 æ¬¡/ç§’)

### æµ‹è¯•åœºæ™¯å®šä¹‰

**åœºæ™¯ 1: å•åº”ç”¨å¹¶å‘è°ƒç”¨**
```python
# æµ‹è¯•è®¾ç½®
- å¹¶å‘ç”¨æˆ·æ•°: 10
- æ¯ç”¨æˆ·è¯·æ±‚æ•°: 10
- æ€»è¯·æ±‚æ•°: 100
- æµ‹è¯•æ—¶é•¿: â‰¤ 1 ç§’
- åº”ç”¨æ•°: 1

# API ç±»å‹åˆ†å¸ƒ
- get_token: 50%
- send_message: 30%
- get_user: 20%

# é¢„æœŸç»“æœ
- æˆåŠŸç‡: â‰¥ 95%
- å¹³å‡å“åº”æ—¶é—´: â‰¤ 500ms
- P99 å“åº”æ—¶é—´: â‰¤ 2s
```

**åœºæ™¯ 2: å¤šåº”ç”¨å¹¶å‘è°ƒç”¨**
```python
# æµ‹è¯•è®¾ç½®
- å¹¶å‘åº”ç”¨æ•°: 5
- æ¯åº”ç”¨è¯·æ±‚æ•°: 20
- æ€»è¯·æ±‚æ•°: 100
- æµ‹è¯•æ—¶é•¿: â‰¤ 1 ç§’

# é¢„æœŸç»“æœ
- åº”ç”¨é—´éš”ç¦»: äº’ä¸å½±å“
- Token æ— å†²çª: æ— å¹¶å‘åˆ·æ–°é”™è¯¯
- æˆåŠŸç‡: â‰¥ 95%
```

### æµ‹è¯•å·¥å…·

**Locust å‹åŠ›æµ‹è¯•**:
```python
# tests/performance/test_concurrent_calls.py
from locust import HttpUser, task, between

class LarkServiceUser(HttpUser):
    wait_time = between(0.1, 0.5)

    def on_start(self):
        """Setup test environment."""
        self.app_id = "cli_test12345678"

    @task(5)
    def get_token(self):
        """Test token acquisition (50% of traffic)."""
        self.client.get(f"/api/token?app_id={self.app_id}")

    @task(3)
    def send_message(self):
        """Test message sending (30% of traffic)."""
        self.client.post("/api/message", json={
            "app_id": self.app_id,
            "receive_id": "ou_test",
            "msg_type": "text",
            "content": "Test message"
        })

    @task(2)
    def get_user(self):
        """Test user query (20% of traffic)."""
        self.client.get(f"/api/user?app_id={self.app_id}&open_id=ou_test")
```

**è¿è¡Œæµ‹è¯•**:
```bash
# å¯åŠ¨ Locust
locust -f tests/performance/test_concurrent_calls.py \
       --host=http://localhost:8000 \
       --users=10 \
       --spawn-rate=10 \
       --run-time=10s \
       --headless

# é¢„æœŸè¾“å‡º
# Name               # reqs      # fails  |     Avg     Min     Max  Median  |   req/s
# ---------------------------------------------------------------------------------
# GET /api/token        500          5     |     150      50     800     120  |    50.0
# POST /api/message     300          3     |     200      80    1200     180  |    30.0
# GET /api/user         200          2     |     180      60     900     150  |    20.0
# ---------------------------------------------------------------------------------
# Aggregated           1000         10     |     170      50    1200     140  |   100.0
#
# âœ… ååé‡: 100 req/s (è¾¾æ ‡)
# âœ… æˆåŠŸç‡: 99.0% (è¾¾æ ‡)
```

---

## ğŸ¯ P002: Token è‡ªåŠ¨å¤„ç†æˆåŠŸç‡ (â‰¥ 99.9%)

### éªŒè¯æ–¹æ³•

**å®šä¹‰**:
- **æˆåŠŸ**: è°ƒç”¨æ–¹æ— éœ€æ‰‹åŠ¨ä»‹å…¥,Token è‡ªåŠ¨è·å–ã€åˆ·æ–°ã€é‡è¯•æˆåŠŸ
- **å¤±è´¥**: éœ€è¦è°ƒç”¨æ–¹æ‰‹åŠ¨é‡è¯•ã€é‡æ–°è·å– Tokenã€æˆ–å¤„ç† Token å¤±æ•ˆé”™è¯¯

**ç»Ÿè®¡å…¬å¼**:
```
è‡ªåŠ¨å¤„ç†æˆåŠŸç‡ = (è‡ªåŠ¨æˆåŠŸæ¬¡æ•° / æ€»è°ƒç”¨æ¬¡æ•°) Ã— 100%
```

**æµ‹è¯•åœºæ™¯**:

1. **æ–° Token è·å–** (è‡ªåŠ¨æˆåŠŸ)
   ```python
   # ç¬¬ä¸€æ¬¡è°ƒç”¨,æ— ç¼“å­˜ Token
   token = pool.get_token("cli_12345678")
   # âœ… è‡ªåŠ¨ä» API è·å–å¹¶ç¼“å­˜
   ```

2. **ç¼“å­˜ Token ä½¿ç”¨** (è‡ªåŠ¨æˆåŠŸ)
   ```python
   # ç¬¬äºŒæ¬¡è°ƒç”¨,Token æœªè¿‡æœŸ
   token = pool.get_token("cli_12345678")
   # âœ… ç›´æ¥è¿”å›ç¼“å­˜ Token
   ```

3. **Token è‡ªåŠ¨åˆ·æ–°** (è‡ªåŠ¨æˆåŠŸ)
   ```python
   # Token å‰©ä½™ 5% ç”Ÿå‘½å‘¨æœŸ
   token = pool.get_token("cli_12345678")
   # âœ… åå°è‡ªåŠ¨åˆ·æ–°,è¿”å›æ–° Token
   ```

4. **Token è¿‡æœŸé‡è¯•** (è‡ªåŠ¨æˆåŠŸ)
   ```python
   # Token å·²è¿‡æœŸ,API è°ƒç”¨å¤±è´¥
   # âœ… è‡ªåŠ¨åˆ·æ–° Token å¹¶é‡è¯•,æˆåŠŸ
   ```

5. **ç½‘ç»œæ•…éšœé‡è¯•** (è‡ªåŠ¨æˆåŠŸ)
   ```python
   # ç½‘ç»œè¶…æ—¶
   # âœ… æŒ‡æ•°é€€é¿é‡è¯•,æˆåŠŸ
   ```

6. **Token æ— æ•ˆ** (è‡ªåŠ¨å¤±è´¥,éœ€æ‰‹åŠ¨ä»‹å…¥)
   ```python
   # App Secret è¢«æ’¤é”€
   # âŒ 3æ¬¡é‡è¯•åä»å¤±è´¥,æŠ›å‡ºå¼‚å¸¸
   ```

**å®ç°ç»Ÿè®¡**:
```python
# src/lark_service/core/credential_pool.py
class CredentialPool:
    def __init__(self, config: Config):
        self.stats = {
            "total_calls": 0,
            "auto_success": 0,
            "manual_required": 0,
        }

    def get_token(self, app_id: str, **kwargs) -> str:
        """Track success rate."""
        self.stats["total_calls"] += 1

        try:
            token = self._get_token_with_retry(app_id, **kwargs)
            self.stats["auto_success"] += 1
            return token
        except TokenAcquisitionError:
            self.stats["manual_required"] += 1
            raise

    def get_success_rate(self) -> float:
        """Calculate auto-handling success rate."""
        if self.stats["total_calls"] == 0:
            return 0.0
        return (self.stats["auto_success"] / self.stats["total_calls"]) * 100
```

**éªŒè¯æµ‹è¯•**:
```python
# tests/integration/test_token_success_rate.py
def test_token_auto_handling_success_rate():
    """Verify â‰¥ 99.9% auto-handling success rate."""
    pool = CredentialPool(config)

    # æ¨¡æ‹Ÿ 10,000 æ¬¡è°ƒç”¨
    total_calls = 10000
    for i in range(total_calls):
        try:
            pool.get_token(f"cli_test{i % 100}")
        except TokenAcquisitionError:
            # ä»…åœ¨ App Secret æ— æ•ˆæ—¶å¤±è´¥
            pass

    # éªŒè¯æˆåŠŸç‡
    success_rate = pool.get_success_rate()
    assert success_rate >= 99.9, f"Success rate {success_rate}% < 99.9%"

    # è¾“å‡ºç»Ÿè®¡
    print(f"""
    Token Auto-Handling Statistics:
    - Total Calls: {pool.stats['total_calls']}
    - Auto Success: {pool.stats['auto_success']}
    - Manual Required: {pool.stats['manual_required']}
    - Success Rate: {success_rate:.2f}%
    """)
```

---

## ğŸ¯ P003: API å“åº”æ—¶é—´ (P99 â‰¤ 2 ç§’)

### æµ‹è¯•æ–¹æ³•

**ä½¿ç”¨ pytest-benchmark**:
```python
# tests/performance/test_response_time.py
import pytest
from lark_service.core.credential_pool import CredentialPool

def test_get_token_response_time(benchmark):
    """Benchmark token acquisition response time."""
    pool = CredentialPool(config)
    app_id = "cli_benchmark_test"

    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    result = benchmark(pool.get_token, app_id)

    # éªŒè¯ P99 å“åº”æ—¶é—´
    stats = benchmark.stats
    p99_time = stats.get("p99", 0)

    assert p99_time <= 2.0, f"P99 response time {p99_time}s > 2s"

    print(f"""
    Response Time Statistics:
    - Min: {stats['min']:.3f}s
    - Max: {stats['max']:.3f}s
    - Mean: {stats['mean']:.3f}s
    - Median: {stats['median']:.3f}s
    - P95: {stats['p95']:.3f}s
    - P99: {p99_time:.3f}s âœ…
    """)
```

**è¿è¡Œæµ‹è¯•**:
```bash
pytest tests/performance/test_response_time.py --benchmark-only

# é¢„æœŸè¾“å‡º
# -------------------------------------------------------------------------
# Name                          Min     Max    Mean  Median    P95    P99
# -------------------------------------------------------------------------
# test_get_token_response_time  0.050   1.800  0.150   0.120  0.500  1.200
# -------------------------------------------------------------------------
# âœ… P99: 1.200s < 2.0s (è¾¾æ ‡)
```

---

## ğŸ¯ P004: Token åˆ·æ–°è€—æ—¶ (â‰¤ 500ms)

### æµ‹è¯•åœºæ™¯

```python
# tests/unit/core/test_token_refresh_performance.py
import time
import pytest

def test_token_refresh_performance():
    """Verify token refresh completes within 500ms."""
    pool = CredentialPool(config)
    app_id = "cli_perf_test12345"

    # é¢„çƒ­: è·å–åˆå§‹ Token
    pool.get_token(app_id)

    # æµ‹è¯•åˆ·æ–°æ€§èƒ½
    start_time = time.time()
    pool.refresh_token(app_id)
    elapsed_time = time.time() - start_time

    # éªŒè¯è€—æ—¶
    assert elapsed_time <= 0.5, f"Refresh time {elapsed_time:.3f}s > 0.5s"

    print(f"Token refresh completed in {elapsed_time:.3f}s âœ…")
```

---

## ğŸ¯ P005: æ•°æ®åº“æŸ¥è¯¢è€—æ—¶ (â‰¤ 50ms)

### æµ‹è¯•åœºæ™¯

```python
# tests/performance/test_database_performance.py
import time

def test_database_query_performance():
    """Verify database queries complete within 50ms."""
    storage = TokenStorageService(config)

    # æµ‹è¯• Token æŸ¥è¯¢
    start_time = time.time()
    token = storage.get_token("cli_db_test", "app_access_token")
    query_time = (time.time() - start_time) * 1000  # Convert to ms

    assert query_time <= 50, f"Query time {query_time:.1f}ms > 50ms"

    print(f"Database query completed in {query_time:.1f}ms âœ…")
```

---

## ğŸ“ˆ æ€§èƒ½ç›‘æ§

### ç”Ÿäº§ç¯å¢ƒç›‘æ§æŒ‡æ ‡

```python
# ä½¿ç”¨ Prometheus ç›‘æ§
from prometheus_client import Counter, Histogram

# è¯·æ±‚è®¡æ•°å™¨
api_requests_total = Counter(
    'api_requests_total',
    'Total API requests',
    ['method', 'endpoint', 'status']
)

# å“åº”æ—¶é—´ç›´æ–¹å›¾
api_response_time = Histogram(
    'api_response_time_seconds',
    'API response time',
    ['method', 'endpoint']
)

# Token åˆ·æ–°è®¡æ•°å™¨
token_refresh_total = Counter(
    'token_refresh_total',
    'Total token refreshes',
    ['app_id', 'token_type', 'result']
)
```

### å‘Šè­¦è§„åˆ™

```yaml
# prometheus/alerts.yml
groups:
  - name: lark_service_performance
    rules:
      # P001: ååé‡ä½äºé˜ˆå€¼
      - alert: LowThroughput
        expr: rate(api_requests_total[1m]) < 100
        for: 5m
        annotations:
          summary: "API throughput below 100 req/s"

      # P002: æˆåŠŸç‡ä½äºé˜ˆå€¼
      - alert: LowSuccessRate
        expr: |
          (
            sum(rate(api_requests_total{status="success"}[5m])) /
            sum(rate(api_requests_total[5m]))
          ) < 0.999
        for: 5m
        annotations:
          summary: "Success rate below 99.9%"

      # P003: P99 å“åº”æ—¶é—´è¶…æ ‡
      - alert: HighResponseTime
        expr: histogram_quantile(0.99, api_response_time_seconds) > 2
        for: 5m
        annotations:
          summary: "P99 response time > 2s"
```

---

## âœ… éªŒæ”¶æ ‡å‡†

### Phase 1 æ€§èƒ½éªŒæ”¶

- [ ] å¹¶å‘æµ‹è¯•è¾¾åˆ° 100 req/s (P001)
- [ ] æˆåŠŸç‡ â‰¥ 99.9% (P002)
- [ ] P99 å“åº”æ—¶é—´ â‰¤ 2s (P003)
- [ ] Token åˆ·æ–° â‰¤ 500ms (P004)
- [ ] æ•°æ®åº“æŸ¥è¯¢ â‰¤ 50ms (P005)

### Phase 2 æ€§èƒ½éªŒæ”¶

- [ ] å‹åŠ›æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
- [ ] æ€§èƒ½ç›‘æ§æŒ‡æ ‡ä¸Šçº¿
- [ ] å‘Šè­¦è§„åˆ™é…ç½®å®Œæˆ
- [ ] æ€§èƒ½ç“¶é¢ˆåˆ†æå’Œä¼˜åŒ–

---

## ğŸ”§ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### æ•°æ®åº“ä¼˜åŒ–

1. **ç´¢å¼•ä¼˜åŒ–**
   ```sql
   -- Token æŸ¥è¯¢ç´¢å¼•
   CREATE INDEX idx_tokens_app_type ON tokens(app_id, token_type);

   -- ç”¨æˆ·ç¼“å­˜ç´¢å¼•
   CREATE INDEX idx_user_cache_app_open ON user_cache(app_id, open_id);
   ```

2. **è¿æ¥æ± é…ç½®**
   ```python
   # PostgreSQL è¿æ¥æ± 
   engine = create_engine(
       DATABASE_URL,
       pool_size=20,          # è¿æ¥æ± å¤§å°
       max_overflow=10,       # æœ€å¤§æº¢å‡ºè¿æ¥
       pool_pre_ping=True,    # è¿æ¥å¥åº·æ£€æŸ¥
       pool_recycle=3600,     # è¿æ¥å›æ”¶æ—¶é—´
   )
   ```

### ç¼“å­˜ä¼˜åŒ–

1. **æœ¬åœ°å†…å­˜ç¼“å­˜**
   ```python
   from functools import lru_cache

   @lru_cache(maxsize=100)
   def get_cached_token(app_id: str, token_type: str) -> str:
       """LRU cache for hot tokens."""
       return pool.get_token(app_id, token_type)
   ```

2. **Token é¢„åŠ è½½**
   ```python
   def warm_up_tokens(app_ids: list[str]) -> None:
       """Pre-fetch tokens for frequently used apps."""
       for app_id in app_ids:
           pool.get_token(app_id)
   ```

---

**ç»´æŠ¤è€…**: Lark Service Team
**å‚è€ƒ**: [performance-requirements.md](./performance-requirements.md)
